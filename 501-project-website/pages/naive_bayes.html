<!DOCTYPE html>
<html>
	<head>
		<title>Naive Bayes</title>
		<link rel="stylesheet" href="../styles.css">
	</head>

	<body>
		
	<!-- HEADER BAR -->
	<ul>
	    <!-- link back to homepage -->
	    <li><a href="../index.html">About me</a></li>

	    <!-- tab without dropdown  -->
	    <li><a href="https://github.com/anly501/anly-501-project-hx33/tree/main/codes">Code</a></li>

	    <!-- tab without dropdown  -->
	    <li><a href="https://github.com/anly501/anly-501-project-hx33/tree/main/data">Data</a></li>

	    <!-- tab without dropdown  -->
	    <li><a href="./portfolio_introduction.html">Introduction</a></li>

	    <!-- tab without dropdown  -->
	    <li><a href="./data_gathering.html">Data Gathering</a></li>

	    <!-- tab with dropdown -->
	    <li><a href="./data_cleaning.html">Data Cleaning</a></li>

	    <!-- tab with dropdown -->
	    <li><a href="./exploring_data.html">Exploring Data</a></li>

	    <!-- tab without dropdown  -->
	    <li><a href="./naive_bayes.html">Naive Bayes</a></li>

	    <!-- tab without dropdown  -->
	    <li><a href="./decision_tree.html">Decision Tree</a></li>

	    <!-- tab without dropdown  -->
	    <li><a href="./SVM.html">SVM</a></li>

	    <!-- <li class="dropdown">
		<a href="javascript:void(0)" class="dropbtn">local reference</a>
		<div class="dropdown-content">
		<a href="./pages/html-cheatsheet/cheatsheet.html">html</a>
		<a href="./pages/markdown-cheatsheet/markdown-cheatsheet.html">markdown</a>
		</div>
	    </li> -->  
	</ul>
		
	<div id="id-of-element-to-link-to">

		<h1  id="C1"><center>Naive Bayes<center/></h1>
			
			<p style="font-size:18px;">
			Naive Bayes methods are a set of supervised learning algorithms that are applying Bayesâ€™ theorem while making naive assumptions that 
				every pairs of variables are independent. It is often used for classification where there are a class variable y and multiple 
				feature vectors. There are some advantages of naive bayes, for instance it learns quickly and only requires small amount of training data.
				This section aims to perform this algorithm on different datasets using both R and Python, and hopes to draw reasonable answers to the data
				questions. 
			</p> <br> <br>
			
		<h2  id="C1"><center>Students Enrollment 2015-2020 Dataset<center/></h2>
			<h3  id="C1">Prepare Dataset for Analysis</h3>
			<p style="font-size:18px;">
			The goal of using Naive Bayes on this dataset is to check whether some variables (grades, races or poverty issues) are related to the difference 
				between the enrollments of girls and boys. To do this the labels that represent the difference should be created as the class variable y.  
			</p> 
			
			<figure class="half" style="display:flex">
			    <img src="../images/NB/dataset1_label.png" width="400" height="119"> <br> <br>
			    <img src="../images/NB/dataset1_labeled.png" width="400" height="119">
			</figure>
			
			<p style="font-size:18px;">
			Therefore, the schools with girls enrollments that's less than 40% of total enrollments will be labeled as 1, with girls enrollments between 
				 40% and 50% of total enrollments labeled as 2, and girls enrollments above 50% labeled as 3. 
			</p>
			
			<p style="font-size:18px;">
			The Naive Bayes model will then use this label as y, and the feature vectors X include either <br>
				1. enrollments for different grades in either elementary, middle or high school, <br>
				2. enrollments for different races. <br>
				
				The dataset will be separated it into training and testing sets. NB will build the classification model after training on the training data, 
				and will make predictions on test data. Then, appropriate visualizations and result summaries will be drawn based on the comparison of the
				predicted labels and the real labels. 
			</p>
			
			<p style="font-size:18px;">
			<a href="../code/NB/nb_dataset_1_R.html">R codes used for Naive Bayes Analysis</a>
			</p>
			<br>
			
			<h3  id="C1">Naive Bayes Analysis on Enrollment Data</h3>
			
			<p style="font-size:18px;">
			A total of 4 tests of Naive Bayes were conducted, with girls enrollment proportion as y label and X features being: <br> 
				1. enrollments for different grades in elementary <br>
				2. enrollments for different grades in middle school <br>
				3. enrollments for different grades in high school <br>
				4. enrollments for different races <br> 
			</p> 
			
			<p style="font-size:18px;">
			The classification results from Naive Bayes are represented in the way of confusion matrices. For each of the 4 tests,
			</p>
			
			<br>
			
			<h4  id="C1"><center>Test 1</center></h4>
			
			<figure class="half" style="display:flex">
			    <img src="../images/NB/dataset1_CM1.png" width="150" height="150"> <br> <br>
			    <img src="../images/NB/NB_dataset1_HM1.png" width="549" height="470">
			</figure>
			
			<p style="font-size:18px;">
			The confusion matrix and related heatmap of classification result with enrollments for different grades in elementary school as X features. 
				The accuracy for this model was 0.55. From the matrix the model successfully classified most of y labels 2 (girls enrollments between 
				 40% and 50% of total enrollments), however when the actual y label is 3 (girls enrollments > 50%), the predictions are very poor.
			</p>
			<br> <br>
			
			<h4  id="C1"><center>Test 2</center></h4>
			
			<figure class="half" style="display:flex">
			    <img src="../images/NB/dataset1_CM2.png" width="150" height="150"> <br> <br>
			    <img src="../images/NB/NB_dataset1_HM2.png" width="549" height="470">
			</figure>
			
			<p style="font-size:18px;">
			The confusion matrix and related heatmap of classification result with enrollments for different grades in middle school as X features. 
				The accuracy for this model was 0.51. From the matrix the model again successfully classified most of y labels 2,
				and when the actual y label is 3, the predictions are very poor.
			</p>
			<br> <br>
			
			<h4  id="C1"><center>Test 3</center></h4>
			
			<figure class="half" style="display:flex">
			    <img src="../images/NB/dataset1_CM3.png" width="150" height="150"> <br> <br>
			    <img src="../images/NB/NB_dataset1_HM3.png" width="549" height="470">
			</figure>
			
			<p style="font-size:18px;">
			The confusion matrix and related heatmap of classification result with enrollments for different grades in high school as X features. The 
				accuracy for this model was 0.54. From the matrix, the model was able to make the right classification for y label 3, however for both
				y label 1 and 2 the model classified most of them also to be 3. 
			</p>
			<br> <br>
			
			<h4  id="C1"><center>Test 4</center></h4>
			
			<figure class="half" style="display:flex">
			    <img src="../images/NB/dataset1_CM4.png" width="150" height="150"> <br> <br>
			    <img src="../images/NB/NB_dataset1_HM4.png" width="549" height="470">
			</figure>
			
			<p style="font-size:18px;">
			The confusion matrix and related heatmap of classification result with enrollments for different races as X features. The 
				accuracy for this model was 0.6. From the matrix, the model was able to make the right classification for y label 2, however for y label 3
				the predictions are extremely poor.
			</p>
			<br> <br>
			
			<h3  id="C1">Conclusion</h3>
			
			<p style="font-size:18px;">
			All the Naive Bayes models used on this dataset did not perform well, with the accuracies slightly over 50%. Since the algorithm could only 
				correctly classify about half of the y labels, it is possible to conclude that the enrollment situation of girls are not really affected 
				by different grades or races. However, it is also possible that Naive Bayes is not a suitable model for the classification job on this 
				particular dataset, since overall it has the "Naive" assumption that every pair of features are conditionally independent. Thus, to find 
				the real answer to the data science questions, deeper models will be used later. 
			</p>
			
			
			
		

				
					
    </div>



	</body>



</html>
