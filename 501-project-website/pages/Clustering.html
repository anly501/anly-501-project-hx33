<!DOCTYPE html>
<html>

	<head>
		<title>Clustering</title>
		<link rel="stylesheet" href="../styles.css">
		<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.0.3/styles/default.min.css">
		<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.0.3/highlight.min.js"></script>
		<script>hljs.initHighlightingOnLoad();</script>
	</head>

	<body>
		
	<!-- HEADER BAR -->
	<ul>
	    <!-- link back to homepage -->
	    <li><a href="../index.html">About me</a></li>

	    <!-- tab without dropdown  -->
	    <li><a href="https://github.com/anly501/anly-501-project-hx33/tree/main/codes">Code</a></li>

	    <!-- tab without dropdown  -->
	    <li><a href="https://github.com/anly501/anly-501-project-hx33/tree/main/data">Data</a></li>

	    <!-- tab without dropdown  -->
	    <li><a href="./portfolio_introduction.html">Introduction</a></li>

	    <!-- tab without dropdown  -->
	    <li><a href="./data_gathering.html">Data Gathering</a></li>

	    <!-- tab with dropdown -->
	    <li><a href="./data_cleaning.html">Data Cleaning</a></li>

	    <!-- tab with dropdown -->
	    <li><a href="./exploring_data.html">Exploring Data</a></li>

	    <!-- tab without dropdown  -->
	    <li><a href="./naive_bayes.html">Naive Bayes</a></li>

	    <!-- tab without dropdown  -->
	    <li><a href="./decision_tree.html">Decision Tree</a></li>

	    <!-- tab without dropdown  -->
	    <li><a href="./SVM.html">SVM</a></li>
		
		<!-- tab without dropdown  -->
	    <li><a href="./Clustering.html">Clustering</a></li>

	    <!-- <li class="dropdown">
		<a href="javascript:void(0)" class="dropbtn">local reference</a>
		<div class="dropdown-content">
		<a href="./pages/html-cheatsheet/cheatsheet.html">html</a>
		<a href="./pages/markdown-cheatsheet/markdown-cheatsheet.html">markdown</a>
		</div>
	    </li> -->  
	</ul>
        
    <div id="id-of-element-to-link-to">

	    <h1  id="C1"><center>Clustering<center/></h1>
			
			<h2  id="C1"><center>Students Enrollment 2015-2020 Dataset<center/></h2>
				
			<p style="font-size:18px;">
			Clustering is the task of grouping a set of data points so that these entries in the same group are more similar to each other than to those 
				in other groups. For this project, clustering is going to solve the questions of: Is the situation of the enrollments difference between
				boys and girls related to the poverty situation of the school?
			</p> 
			
			<p style="font-size:18px;">
			To answer this question, the feature data X is going to be: the enrollments numbers of boys and girls of the school, and the number of poverty
				enrollments of the schools. Since clustering is an unsupervised algorithm, there is no y-label. 
			</p> 
				
			<figure class="half" style="display:flex">
			    <img src="../images/Cluster/Cl_Dataset1_X1.png" width="645" height="161"> 
			    <img src="../images/Cluster/Cl_Dataset1_X2.png" width="164" height="161">
			</figure>
			
			<br> <br>
				
			<h3  id="C1">Theory</h3>
				
			<h4  id="C1"><center>K-Means</center></h4>
				
			<p style="font-size:18px;">
			Probably the most commonly used clustering method, K-means works by first selecting k points as the center points of the clusters, and then
				calculate the distance from the k center points to the data points so for each data point the nearest center point can be found. 
			</p>
				
			<p style="font-size:18px;">
			Then the algorithm will start to update the center points, by calculate an intermediate point for each of the clusters, make it become the new
				center point of the clusters and keep updating until the distance calculated above is small enough. At this time the clusters are determined.
			</p>
				
			<h4  id="C1"><center>Elbow Method</center></h4>
				
			<p style="font-size:18px;">
			For K-means clustering the elbow method is an useful way to find the optimal number of clusters base on plots. The inertia 
				is a measure of how the clustering is performing on the features, and since the ideal model is supposed to have both low number of
				clusters and low inertia, the "elbow point" by looking at the graph provides the ultimate K. 
			</p>
				
			<h3  id="C1">Methods</h3>
				
			<h4  id="C1">Hyper-parameter tuning for K-Means</h4>
			
			<p style="font-size:18px;">
			For K-means clustering, I will first use the elbow method for hyper-parameter tuning to find the optimal number of clusters. After fitting the X-features,
				the inertia of the model vs. the K numbers in a range of 1 to 10 will be plotted in order to find the best number of K. The results of the
				elbow method are shown below on the left: 
			</p>
				
			<figure class="half" style="display:flex">
			    <img src="../images/Cluster/Cl_Dataset1_Inertia1.png" width="450" height="287"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 
			    <img src="../images/Cluster/Cl_Dataset1_Cluster1.png" width="450" height="345">
			</figure>
				
			<p style="font-size:18px;">
			From the plot, the "elbow" of the K-Means model is at 4, therefore K=4 is the best number of clusters. Then, using this parameter the result of 
				the cluster model is shown on the right: the data points enrollments of girls and poverty students are separated into 4 groups.  
			</p>
			
			<br> <br>
				
			<h4  id="C1">Hyper-parameter tuning for Hierarchical Clustering</h4>
				
			<p style="font-size:18px;">
			For hierarchical clustering, I will first use the Silhouette method for hyper-parameter tuning to find the optimal number of clusters. 
				After fitting the X-features, the Silhouette scores of the model vs. the K numbers in a range of 1 to 10 will be plotted in order to 
				find the best number of K. The plot of the Silhouette method is shown below on the left. Secondly, a dendrogram plot for the linkage 
				for the hierarchical clustering will be used to plot the clusters, and to suggest the optimal number of clusters. The dendrogram is shown
				on the right:
			</p>
				
			<figure class="half" style="display:flex">
			    <img src="../images/Cluster/Cl_Dataset1_Sil1.png" width="450" height="360"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 
			    <img src="../images/Cluster/Cl_Dataset1_Den1.png" width="450" height="447">
			</figure>
				
			<p style="font-size:18px;">
			The results from the Silhouette method and the dendrogram both suggests that 2 would be the optimal number of clusters, with 4 being the second
				best. Thus, the results here are not too different comparing to the elbow method of K-Means method. 
			</p>
			
			<h3  id="C1">Conclusion</h3>
			
			<p style="font-size:18px;">
			To wrap up, for the K-Means and hierarchical clustering it is determined that k=4 would be a good estimate of the number of clusters. From the
				result plot of the clusters for K-Means clustering, it is shown that the data points of enrollments numbers of girls and poverty students
				can be grouped into 4 clusters clearly, and the Silhouette scores of this classification is decent (0.6). This might suggest that the 
				poverty situation of the school is related to how the enrollments situation is for the girls. 
			</p>
		
		
	</div>

	</body>

</html>
